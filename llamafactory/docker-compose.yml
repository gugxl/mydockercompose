
services:
  llamafactory:
    image: hiyouga/llamafactory:latest
    container_name: llamafactory
    restart: unless-stopped
    ports:
      - "7860:7860"
    environment:
      - HF_ENDPOINT=https://hf-mirror.com
    command: >
      python -m src.llamafactory.cli webui
      --host 0.0.0.0
      --port 7860
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    ipc: host
    volumes:
      - ./data:/app/data
      - ./hf_cache:/root/.cache/huggingface
