version: '3.8'

services:
  # 1. Zookeeper
  zookeeper:
    image: zookeeper:3.6.3
    container_name: gugu-zookeeper
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    ports:
      - "2181:2181"
    networks:
      - hadoop_network
    volumes:
      - zookeeper_data:/data
    healthcheck:
      test: ["CMD", "echo", "ruok", "|", "nc", "localhost", "2181"]
      interval: 5s
      timeout: 5s
      retries: 10

  # 2. HDFS NameNode
  namenode:
    image: apache/hadoop:3.3.6
    container_name: gugu-namenode
    #    restart: always
    ports:
      - "9870:9870" # HDFS NameNode UI
      - "9000:9000" # HDFS RPC port
    volumes:
      - namenode_data:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=hadoop-dev-cluster
      - CORE_CONF_fs_defaultFS='hdfs://namenode:9000'
    env_file:
      - ./hadoop.env
    networks:
      - hadoop_network
    command: ["sh", "-c", "
      # 格式化HDFS (只在第一次启动时执行)
      if [ ! -f /hadoop/dfs/name/current/VERSION ]; then
        hdfs namenode -format -nonInteractive
      fi
      # 启动NameNode
      hdfs namenode
    "]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9870/"]
      interval: 30s
      timeout: 10s
      retries: 5

  # 3. HDFS DataNode
  datanode:
    image: apache/hadoop:3.3.6
    container_name: gugu-datanode
    #    restart: always
    depends_on:
      - namenode
    volumes:
      - datanode_data:/hadoop/dfs/data
    env_file:
      - ./hadoop.env
    environment:
      - HDFS_NAMENODE_HOST=namenode
    networks:
      - hadoop_network
    command: ["hdfs", "datanode"]
    healthcheck:
      test: ["CMD-SHELL", "hdfs dfsadmin -report | grep -q 'Live datanodes'"]
      interval: 30s
      timeout: 10s
      retries: 5

  # 4. YARN ResourceManager
  resourcemanager:
    image: apache/hadoop:3.3.6
    container_name: gugu-resourcemanager
    #    restart: always
    depends_on:
      - namenode
      - datanode
    ports:
      - "8088:8088" # YARN ResourceManager UI
    env_file:
      - ./hadoop.env
    networks:
      - hadoop_network
    command: ["yarn", "resourcemanager"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8088/"]
      interval: 30s
      timeout: 10s
      retries: 5

  # 5. YARN NodeManager
  nodemanager:
    image: apache/hadoop:3.3.6
    container_name: gugu-nodemanager
    #    restart: always
    depends_on:
      - namenode
      - datanode
      - resourcemanager
    env_file:
      - ./hadoop.env
    environment:
      - YARN_RESOURCEMANAGER_HOSTNAME=resourcemanager
    networks:
      - hadoop_network
    command: ["yarn", "nodemanager"]
    healthcheck:
      test: ["CMD-SHELL", "yarn node -list | grep -q 'RUNNING'"]
      interval: 30s
      timeout: 10s
      retries: 5

  # 6. Postgresql for Hive Metastore
  postgresql:
    image: bitnami/postgresql:14.18.0
    container_name: postgresql
    hostname: postgresql
    ports:
      - "5432:5432"
    environment:
      - POSTGRESQL_USERNAME=hive
      - POSTGRESQL_PASSWORD=hive
      - POSTGRESQL_DATABASE=hive_metastore
    volumes:
      - postgresql-data:/bitnami/postgresql
    networks:
      - hadoop_network
    depends_on:
      - zookeeper
    #    restart: always
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "hive"]
      interval: 5s
      timeout: 5s
      retries: 10

  # 7. Hive Metastore Initialization (一次性任务)
  hive-metastore-init:
    image: apache/hive:3.1.3
    container_name: hive-metastore-init
    command: ["/bin/bash", "-c", "
      # 等待PostgreSQL和HDFS就绪
      until nc -z postgresql 5432; do sleep 1; done
      until curl -f http://namenode:9870/; do sleep 1; done
      
      # 初始化HDFS上的Hive仓库目录
      hdfs dfs -mkdir -p /user/hive/warehouse
      hdfs dfs -chmod g+w /user/hive/warehouse
      hdfs dfs -mkdir -p /tmp
      hdfs dfs -chmod g+w /tmp
      
      # 尝试修复环境变量格式问题
      export HIVE_CONF_hive_site_hbase_rootdir='hdfs://namenode:9000/hbase'
      
      # 初始化Hive Metastore数据库
      /opt/apache-hive-3.1.3-bin/bin/schematool -dbType postgresql -initSchema
    "]
    depends_on:
      - postgresql
      - namenode
    environment:
      - HIVE_METASTORE_DB_HOSTNAME=postgresql
      - HIVE_METASTORE_DB_PORT=5432
      - HIVE_METASTORE_DB_USERNAME=hive
      - HIVE_METASTORE_DB_PASSWORD=hive
      - HIVE_METASTORE_WAREHOUSE_DIR=hdfs://namenode:9000/user/hive/warehouse
      # 避免环境变量中包含=符号
      - HIVE_CONF_hive_site_hbase_zookeeper_quorum=zookeeper:2181
      - HIVE_CONF_hive_site_hbase_cluster_distributed=true
      - HIVE_CONF_hive_site_hbase_rootdir=hdfs://namenode:9000/hbase
    networks:
      - hadoop_network
    restart: "no"

  # 8. Hive Metastore Service
  hive-metastore:
    image: apache/hive:3.1.3
    container_name: gugu-hive-metastore
    command: ["/bin/bash", "-c", "
      # 尝试修复环境变量格式问题
      export HIVE_CONF_hive_site_hbase_rootdir='hdfs://namenode:9000/hbase'
      
      # 启动Hive Metastore服务
      /opt/apache-hive-3.1.3-bin/bin/hive --service metastore
    "]
    depends_on:
      - postgresql
      - namenode
      - hive-metastore-init
    environment:
      - HIVE_METASTORE_DB_HOSTNAME=postgresql
      - HIVE_METASTORE_DB_PORT=5432
      - HIVE_METASTORE_DB_USERNAME=hive
      - HIVE_METASTORE_DB_PASSWORD=hive
      - HIVE_METASTORE_WAREHOUSE_DIR=hdfs://namenode:9000/user/hive/warehouse
      # 避免环境变量中包含=符号
      - HIVE_CONF_hive_site_hbase_zookeeper_quorum=zookeeper:2181
      - HIVE_CONF_hive_site_hbase_cluster_distributed=true
      - HIVE_CONF_hive_site_hbase_rootdir=hdfs://namenode:9000/hbase
    ports:
      - "9083:9083"
    networks:
      - hadoop_network
    #    restart: always
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "9083"]
      interval: 30s
      timeout: 10s
      retries: 5

  # 9. HiveServer2
  hive-server:
    image: apache/hive:3.1.3
    container_name: gugu-hive-server
    command: ["/bin/bash", "-c", "
      # 等待Hive Metastore就绪
      until nc -z hive-metastore 9083; do sleep 1; done
      
      # 启动HiveServer2
      /opt/apache-hive-3.1.3-bin/bin/hiveserver2
    "]
    depends_on:
      - hive-metastore
      - resourcemanager
    environment:
      - HIVE_METASTORE_URIS=thrift://hive-metastore:9083
      - SERVICE_NAME=hiveserver2
    ports:
      - "10000:10000"
      - "10002:10002"
    networks:
      - hadoop_network
    #    restart: always
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "10000"]
      interval: 30s
      timeout: 10s
      retries: 5

  # 10. HBase Master
  hbase-master:
    image: openeuler/hbase:2.6.2-oe2403sp1
    container_name: hbase-master
    #    restart: always
    depends_on:
      - namenode
      - zookeeper
    ports:
      - "16010:16010"
      - "16000:16000"
    environment:
      - HBASE_CONF_hbase_site_hbase_zookeeper_quorum=zookeeper:2181
      - HBASE_CONF_hbase_site_hbase_cluster_distributed=true
      - HBASE_CONF_hbase_site_hbase_rootdir=hdfs://namenode:9000/hbase
      - HBASE_MASTER_INFO_PORT=16010
    volumes:
      - hbase_master_data:/opt/hbase/data
    networks:
      - hadoop_network
    command: ["hbase", "master", "start"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:16010/"]
      interval: 30s
      timeout: 10s
      retries: 5

  # 11. HBase RegionServer
  hbase-regionserver:
    image: openeuler/hbase:2.6.2-oe2403sp1
    container_name: hbase-regionserver
    #    restart: always
    depends_on:
      - hbase-master
    environment:
      - HBASE_CONF_hbase_site_hbase_zookeeper_quorum=zookeeper:2181
      - HBASE_CONF_hbase_site_hbase_cluster_distributed=true
      - HBASE_CONF_hbase_site_hbase_rootdir=hdfs://namenode:9000/hbase
    volumes:
      - hbase_regionserver_data:/opt/hbase/data
    networks:
      - hadoop_network
    command: ["hbase", "regionserver", "start"]
    healthcheck:
      test: ["CMD-SHELL", "hbase shell -e 'status' | grep -q 'live servers'"]
      interval: 30s
      timeout: 10s
      retries: 5

  # 12. Spark Master
  spark-master:
    image: apache/spark:3.4.1
    container_name: spark-master
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.master.Master", "-h", "spark-master"]
    ports:
      - "8080:8080"
      - "7077:7077"
    networks:
      - hadoop_network
    environment:
      - SPARK_MASTER_HOST=spark-master
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/"]
      interval: 30s
      timeout: 10s
      retries: 5

  # 13. Spark Worker
  spark-worker:
    image: apache/spark:3.4.1
    container_name: spark-worker
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077"]
    depends_on:
      - spark-master
    networks:
      - hadoop_network
    environment:
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8081/ | grep -q 'Worker'"]
      interval: 30s
      timeout: 10s
      retries: 5

  # 14. Spark History Server
  spark-history-server:
    image: apache/spark:3.4.1
    container_name: spark-history-server
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.history.HistoryServer"]
    depends_on:
      - namenode
    ports:
      - "18080:18080"
    environment:
      - SPARK_HISTORY_OPTS="-Dspark.history.fs.logDirectory=hdfs://namenode:9000/spark-events"
    networks:
      - hadoop_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:18080/"]
      interval: 30s
      timeout: 10s
      retries: 5

volumes:
  zookeeper_data:
  namenode_data:
  datanode_data:
  postgresql-data:
  hbase_master_data:
  hbase_regionserver_data:

networks:
  hadoop_network:
    driver: bridge
